Retrieval-Augmented Generation (RAG) for Book-Based Question Answering
📖 A Collaboration with AKA Foods

📌 Project Overview
This project implements an advanced Retrieval-Augmented Generation (RAG) system to answer questions from a specific book using fusion retrieval, hierarchical indices, adaptive retrieval, and RAPTOR techniques. The system is designed to enhance knowledge retrieval by combining semantic search, adaptive indexing, and optimized context retrieval with OpenAI embeddings and FAISS vector search for highly accurate and context-aware responses.

This work is based on Nir Diamant’s repository, leveraging and extending his approach to RAG for book-based question answering.

⚙️ Technology Stack
LLMs: OpenAI GPT Models
Vector Database: FAISS
Embeddings Model: OpenAI Embeddings
Frameworks & Libraries: LangChain, OpenAI API
Deployment: FastAPI (for API access), Streamlit (for UI)
Advanced Retrieval Techniques:
✅ Fusion Retrieval – Combining multiple retrieval strategies for better relevance
✅ Hierarchical Indices – Structuring embeddings to improve efficiency
✅ Adaptive Retrieval – Dynamically adjusting retrieval based on query complexity
✅ RAPTOR – Optimized query processing for enhanced response quality
🔬 Future Enhancements
🔹 Multi-document Support – Expanding beyond a single book
🔹 Fine-tuned Query Expansion – Improving retrieval accuracy for complex questions
🔹 Custom Fine-tuning of LLM – Adapting responses based on specific domain knowledge

