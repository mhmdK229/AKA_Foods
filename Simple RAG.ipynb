{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f0b7b5",
   "metadata": {},
   "source": [
    "# **Retrieval-Augmented Generation (RAG) System**\n",
    "\n",
    "## **Objective**\n",
    "The goal of this project was to implement a **Retrieval-Augmented Generation (RAG)** system to answer user queries by retrieving relevant context from a **PDF book**.\n",
    "\n",
    "## **Process Overview**\n",
    "\n",
    "### 1. **PDF Processing**\n",
    "We used **LangChain's `PyPDFLoader`** to load the content of the PDF and split it into manageable **chunks** using the **`RecursiveCharacterTextSplitter`**. This helps in making the document easier to process and retrieve information from.\n",
    "\n",
    "### 2. **Embedding the Content**\n",
    "- **SentenceTransformers** was used to embed the text chunks into **vectors** using the \"all-MiniLM-L6-v2\" model.\n",
    "- These embeddings were stored in **FAISS**, a vector store that enables **efficient similarity search**.\n",
    "\n",
    "### 3. **Context Retrieval**\n",
    "- For each user **query**, the question was converted into an **embedding vector**.\n",
    "- The **FAISS vector store** (with **LangChain retriever**) was used to search for the most relevant document chunks by measuring **semantic similarity** between the question and the document embeddings.\n",
    "\n",
    "### 4. **Integration**\n",
    "- The retriever, vector store, and embedding model were combined into a complete system that could retrieve relevant document content and generate an answer for the query.\n",
    "\n",
    "## **Libraries and Tools Used**\n",
    "\n",
    "- **LangChain**: For document loading, embedding management, and creating a retriever.\n",
    "- **FAISS**: To store and search for embeddings efficiently.\n",
    "- **SentenceTransformers**: To convert text into vector embeddings.\n",
    "- **PyPDFLoader**: To read and load the PDF document.\n",
    "- **RecursiveCharacterTextSplitter**: To break the document into chunks for easier processing.\n",
    "\n",
    "## **Outcome**\n",
    "- We successfully built a **RAG system** capable of processing a large PDF, embedding its content, and answering queries based on semantic similarity.\n",
    "- The system retrieves relevant context from the document and generates answers based on the retrieved information.\n",
    "\n",
    "## **Challenges Faced**\n",
    "- Efficient **chunking** and **embedding** of large documents.\n",
    "- Ensuring **semantic retrieval**, not just keyword matching, for accurate answers.\n",
    "- Setting up the correct **environment** and handling dependencies.\n",
    "\n",
    "## **Final Thoughts**\n",
    "- This **RAG system** using **LangChain** and **FAISS** allows us to retrieve and generate information based on semantic meaning, making it an efficient way to handle large documents for question-answering systems.\n",
    "- The setup can be further improved with **fine-tuned models**, **chunking strategies**, and better **query processing**.\n",
    "\n",
    "---\n",
    "\n",
    "**Let’s continue building and improving this powerful system for larger, more complex datasets!**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76468747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from helper_functions import *\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f830b",
   "metadata": {},
   "source": [
    "# Read Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d25c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"AKA Book.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8942dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pdf(path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Encodes a PDF book into a vector store using SentenceTransformers embeddings.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the PDF file.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded book content.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Load PDF documents\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Step 2: Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Step 3: Clean text (optional, if a function like replace_t_with_space exists in your code)\n",
    "    cleaned_texts = replace_t_with_space(texts) if 'replace_t_with_space' in globals() else texts\n",
    "\n",
    "    # Step 4: Initialize the SentenceTransformer model\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Free embedding model\n",
    "\n",
    "    # Step 5: Use HuggingFaceEmbeddings wrapper to handle SentenceTransformer model\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    # Step 6: Create FAISS vector store\n",
    "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e5641ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_39080\\1931561439.py:29: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "chunks_vector_store = encode_pdf(path, chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ca6a8",
   "metadata": {},
   "source": [
    "### Create retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2ed80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd79f9",
   "metadata": {},
   "source": [
    "### Test Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f6e09f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "Beckett’s Industrial Chocolate  \n",
      "Manufacture and Use\n",
      "\n",
      "\n",
      "Context 2:\n",
      "Beckett’s Industrial \n",
      "Chocolate \n",
      "Manufacture \n",
      "and Use\n",
      "FIFTH EDITION\n",
      "EDITED BY\n",
      "Stephen T. Beckett\n",
      "Mark S. Fowler\n",
      "Gregory R. Ziegler\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_query = \"Who edited the book 'Beckett's Industrial Chocolate Manufacture and Use'\"\n",
    "context = retrieve_context_per_question(test_query, chunks_query_retriever)\n",
    "show_context(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e98e1fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_env)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
